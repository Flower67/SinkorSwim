{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(314)\n",
    "tf.random.set_seed(314)\n",
    "random.seed(314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    # shuffle two arrays in the same way\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n",
    "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
    "    \"\"\"\n",
    "    Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n",
    "    Params:\n",
    "        ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n",
    "        n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n",
    "        scale (bool): whether to scale prices from 0 to 1, default is True\n",
    "        shuffle (bool): whether to shuffle the dataset (both training & testing), default is True\n",
    "        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n",
    "        split_by_date (bool): whether we split the dataset into training/testing by date, setting it \n",
    "            to False will split datasets in a random way\n",
    "        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
    "        feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n",
    "    \"\"\"\n",
    "    # see if ticker is already a loaded stock from yahoo finance\n",
    "    if isinstance(ticker, str):\n",
    "        # load it from yahoo_fin library\n",
    "        df = si.get_data(ticker)\n",
    "    elif isinstance(ticker, pd.DataFrame):\n",
    "        # already loaded, use it directly\n",
    "        df = ticker\n",
    "    else:\n",
    "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
    "    # this will contain all the elements we want to return from this function\n",
    "    result = {}\n",
    "    # we will also return the original dataframe itself\n",
    "    result['df'] = df.copy()\n",
    "    # make sure that the passed feature_columns exist in the dataframe\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "    # add date as a column\n",
    "    if \"date\" not in df.columns:\n",
    "        df[\"date\"] = df.index\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        # scale the data (prices) from 0 to 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "        # add the MinMaxScaler instances to the result returned\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "    # add the target column (label) by shifting by `lookup_step`\n",
    "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
    "    # last `lookup_step` columns contains NaN in future column\n",
    "    # get them before droping NaNs\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    # drop NaNs\n",
    "    df.dropna(inplace=True)\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
    "    # this last_sequence will be used to predict future stock prices that are not available in the dataset\n",
    "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "    # add to result\n",
    "    result['last_sequence'] = last_sequence\n",
    "    # construct the X's and y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    # convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    if split_by_date:\n",
    "        # split the dataset into training & testing sets by date (not randomly splitting)\n",
    "        train_samples = int((1 - test_size) * len(X))\n",
    "        result[\"X_train\"] = X[:train_samples]\n",
    "        result[\"y_train\"] = y[:train_samples]\n",
    "        result[\"X_test\"]  = X[train_samples:]\n",
    "        result[\"y_test\"]  = y[train_samples:]\n",
    "        if shuffle:\n",
    "            # shuffle the datasets for training (if shuffle parameter is set)\n",
    "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
    "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
    "    else:    \n",
    "        # split the dataset randomly\n",
    "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
    "                                                                                test_size=test_size, shuffle=shuffle)\n",
    "    # get the list of test set dates\n",
    "    dates = result[\"X_test\"][:, -1, -1]\n",
    "    # retrieve test features from the original dataframe\n",
    "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "    # remove duplicated dates in the testing dataframe\n",
    "    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
    "    # remove dates from the training/testing sets & convert to float32\n",
    "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 50\n",
    "# Lookup step, 1 is the next day\n",
    "LOOKUP_STEP = 15\n",
    "# whether to scale feature columns & output price as well\n",
    "SCALE = True\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "# whether to shuffle the dataset\n",
    "SHUFFLE = True\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "# whether to split the training/testing set by date\n",
    "SPLIT_BY_DATE = False\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.2\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "### model parameters\n",
    "N_LAYERS = 2\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "# 40% dropout\n",
    "DROPOUT = 0.4\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "### training parameters\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 500\n",
    "# Amazon stock market\n",
    "ticker = \"AMZN\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "74/74 [==============================] - 16s 189ms/step - loss: 0.0035 - mean_absolute_error: 0.0334 - val_loss: 2.0857e-04 - val_mean_absolute_error: 0.0149\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00021, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 2/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 5.3711e-04 - mean_absolute_error: 0.0168 - val_loss: 1.5306e-04 - val_mean_absolute_error: 0.0108\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00021 to 0.00015, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 3/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 3.6521e-04 - mean_absolute_error: 0.0129 - val_loss: 2.1439e-04 - val_mean_absolute_error: 0.0152\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00015\n",
      "Epoch 4/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 4.5754e-04 - mean_absolute_error: 0.0164 - val_loss: 1.2894e-04 - val_mean_absolute_error: 0.0084\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00015 to 0.00013, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 5/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 3.8353e-04 - mean_absolute_error: 0.0136 - val_loss: 1.2409e-04 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00013 to 0.00012, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 6/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 3.9677e-04 - mean_absolute_error: 0.0139 - val_loss: 4.2242e-04 - val_mean_absolute_error: 0.0160\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00012\n",
      "Epoch 7/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 5.1182e-04 - mean_absolute_error: 0.0159 - val_loss: 2.9014e-04 - val_mean_absolute_error: 0.0164\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00012\n",
      "Epoch 8/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 4.1902e-04 - mean_absolute_error: 0.0149 - val_loss: 1.9489e-04 - val_mean_absolute_error: 0.0107\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00012\n",
      "Epoch 9/500\n",
      "74/74 [==============================] - 14s 184ms/step - loss: 3.1114e-04 - mean_absolute_error: 0.0126 - val_loss: 1.3962e-04 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00012\n",
      "Epoch 10/500\n",
      "74/74 [==============================] - 14s 186ms/step - loss: 3.7858e-04 - mean_absolute_error: 0.0133 - val_loss: 1.2300e-04 - val_mean_absolute_error: 0.0080\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00012 to 0.00012, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 11/500\n",
      "74/74 [==============================] - 14s 183ms/step - loss: 3.3818e-04 - mean_absolute_error: 0.0129 - val_loss: 1.4514e-04 - val_mean_absolute_error: 0.0081\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00012\n",
      "Epoch 12/500\n",
      "74/74 [==============================] - 14s 185ms/step - loss: 3.2498e-04 - mean_absolute_error: 0.0126 - val_loss: 2.0432e-04 - val_mean_absolute_error: 0.0121\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00012\n",
      "Epoch 13/500\n",
      "74/74 [==============================] - 14s 185ms/step - loss: 3.6928e-04 - mean_absolute_error: 0.0140 - val_loss: 1.4329e-04 - val_mean_absolute_error: 0.0079\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00012\n",
      "Epoch 14/500\n",
      "74/74 [==============================] - 14s 184ms/step - loss: 2.9368e-04 - mean_absolute_error: 0.0120 - val_loss: 1.4184e-04 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00012\n",
      "Epoch 15/500\n",
      "74/74 [==============================] - 14s 185ms/step - loss: 3.5181e-04 - mean_absolute_error: 0.0130 - val_loss: 1.1994e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00012 to 0.00012, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 16/500\n",
      "74/74 [==============================] - 14s 183ms/step - loss: 3.1796e-04 - mean_absolute_error: 0.0123 - val_loss: 1.1689e-04 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00012 to 0.00012, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 17/500\n",
      "74/74 [==============================] - 13s 180ms/step - loss: 3.0425e-04 - mean_absolute_error: 0.0125 - val_loss: 1.1726e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00012\n",
      "Epoch 18/500\n",
      "74/74 [==============================] - 14s 185ms/step - loss: 3.2025e-04 - mean_absolute_error: 0.0125 - val_loss: 1.4390e-04 - val_mean_absolute_error: 0.0099\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00012\n",
      "Epoch 19/500\n",
      "74/74 [==============================] - 14s 185ms/step - loss: 3.5158e-04 - mean_absolute_error: 0.0139 - val_loss: 1.4325e-04 - val_mean_absolute_error: 0.0090\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00012\n",
      "Epoch 20/500\n",
      "74/74 [==============================] - 14s 184ms/step - loss: 3.1482e-04 - mean_absolute_error: 0.0124 - val_loss: 1.5708e-04 - val_mean_absolute_error: 0.0082\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00012\n",
      "Epoch 21/500\n",
      "74/74 [==============================] - 14s 189ms/step - loss: 2.8230e-04 - mean_absolute_error: 0.0125 - val_loss: 1.6252e-04 - val_mean_absolute_error: 0.0082\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00012\n",
      "Epoch 22/500\n",
      "74/74 [==============================] - 14s 196ms/step - loss: 3.3217e-04 - mean_absolute_error: 0.0129 - val_loss: 1.3524e-04 - val_mean_absolute_error: 0.0082\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00012\n",
      "Epoch 23/500\n",
      "74/74 [==============================] - 14s 186ms/step - loss: 2.6732e-04 - mean_absolute_error: 0.0119 - val_loss: 1.2167e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00012\n",
      "Epoch 24/500\n",
      "74/74 [==============================] - 14s 183ms/step - loss: 2.9471e-04 - mean_absolute_error: 0.0123 - val_loss: 1.1870e-04 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00012\n",
      "Epoch 25/500\n",
      "74/74 [==============================] - 14s 184ms/step - loss: 3.1252e-04 - mean_absolute_error: 0.0130 - val_loss: 1.2522e-04 - val_mean_absolute_error: 0.0083\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00012\n",
      "Epoch 26/500\n",
      "74/74 [==============================] - 14s 189ms/step - loss: 3.4529e-04 - mean_absolute_error: 0.0132 - val_loss: 1.3072e-04 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00012\n",
      "Epoch 27/500\n",
      "74/74 [==============================] - 14s 190ms/step - loss: 2.7778e-04 - mean_absolute_error: 0.0121 - val_loss: 1.1946e-04 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00012\n",
      "Epoch 28/500\n",
      "74/74 [==============================] - 14s 194ms/step - loss: 2.5233e-04 - mean_absolute_error: 0.0120 - val_loss: 1.2612e-04 - val_mean_absolute_error: 0.0084\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00012\n",
      "Epoch 29/500\n",
      "74/74 [==============================] - 14s 195ms/step - loss: 2.6011e-04 - mean_absolute_error: 0.0118 - val_loss: 1.5513e-04 - val_mean_absolute_error: 0.0087\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00012\n",
      "Epoch 30/500\n",
      "74/74 [==============================] - 14s 188ms/step - loss: 2.4814e-04 - mean_absolute_error: 0.0119 - val_loss: 1.2650e-04 - val_mean_absolute_error: 0.0088\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00012\n",
      "Epoch 31/500\n",
      "74/74 [==============================] - 14s 187ms/step - loss: 3.0286e-04 - mean_absolute_error: 0.0128 - val_loss: 1.6625e-04 - val_mean_absolute_error: 0.0085\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00012\n",
      "Epoch 32/500\n",
      "74/74 [==============================] - 14s 193ms/step - loss: 2.7720e-04 - mean_absolute_error: 0.0121 - val_loss: 2.0502e-04 - val_mean_absolute_error: 0.0093\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00012\n",
      "Epoch 33/500\n",
      "74/74 [==============================] - 14s 193ms/step - loss: 3.2968e-04 - mean_absolute_error: 0.0129 - val_loss: 1.6542e-04 - val_mean_absolute_error: 0.0095\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00012\n",
      "Epoch 34/500\n",
      "74/74 [==============================] - 14s 193ms/step - loss: 2.5472e-04 - mean_absolute_error: 0.0119 - val_loss: 2.0752e-04 - val_mean_absolute_error: 0.0103\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00012\n",
      "Epoch 35/500\n",
      "74/74 [==============================] - 14s 193ms/step - loss: 2.6325e-04 - mean_absolute_error: 0.0122 - val_loss: 1.4692e-04 - val_mean_absolute_error: 0.0088\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00012\n",
      "Epoch 36/500\n",
      "74/74 [==============================] - 14s 187ms/step - loss: 2.8660e-04 - mean_absolute_error: 0.0125 - val_loss: 2.1257e-04 - val_mean_absolute_error: 0.0090\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00012\n",
      "Epoch 37/500\n",
      "74/74 [==============================] - 14s 190ms/step - loss: 3.0474e-04 - mean_absolute_error: 0.0133 - val_loss: 1.1635e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00012 to 0.00012, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 38/500\n",
      "74/74 [==============================] - 14s 193ms/step - loss: 2.4966e-04 - mean_absolute_error: 0.0121 - val_loss: 1.1923e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00012\n",
      "Epoch 39/500\n",
      "74/74 [==============================] - 14s 193ms/step - loss: 3.1939e-04 - mean_absolute_error: 0.0130 - val_loss: 1.2965e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00012\n",
      "Epoch 40/500\n",
      "74/74 [==============================] - 14s 188ms/step - loss: 2.8204e-04 - mean_absolute_error: 0.0125 - val_loss: 1.2376e-04 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00012\n",
      "Epoch 41/500\n",
      "74/74 [==============================] - 14s 192ms/step - loss: 3.2074e-04 - mean_absolute_error: 0.0132 - val_loss: 1.6000e-04 - val_mean_absolute_error: 0.0091\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00012\n",
      "Epoch 42/500\n",
      "74/74 [==============================] - 14s 195ms/step - loss: 2.7900e-04 - mean_absolute_error: 0.0131 - val_loss: 1.7522e-04 - val_mean_absolute_error: 0.0107\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.00012\n",
      "Epoch 43/500\n",
      "74/74 [==============================] - 14s 186ms/step - loss: 3.0765e-04 - mean_absolute_error: 0.0134 - val_loss: 1.1963e-04 - val_mean_absolute_error: 0.0080\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00012\n",
      "Epoch 44/500\n",
      "74/74 [==============================] - 14s 186ms/step - loss: 2.9542e-04 - mean_absolute_error: 0.0131 - val_loss: 1.3375e-04 - val_mean_absolute_error: 0.0080\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00012\n",
      "Epoch 45/500\n",
      "74/74 [==============================] - 14s 184ms/step - loss: 2.9977e-04 - mean_absolute_error: 0.0130 - val_loss: 1.7265e-04 - val_mean_absolute_error: 0.0094\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00012\n",
      "Epoch 46/500\n",
      "74/74 [==============================] - 14s 186ms/step - loss: 2.7334e-04 - mean_absolute_error: 0.0126 - val_loss: 1.1910e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00012\n",
      "Epoch 47/500\n",
      "74/74 [==============================] - 14s 188ms/step - loss: 2.8123e-04 - mean_absolute_error: 0.0128 - val_loss: 1.2333e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00012\n",
      "Epoch 48/500\n",
      "74/74 [==============================] - 14s 187ms/step - loss: 2.4917e-04 - mean_absolute_error: 0.0119 - val_loss: 1.4065e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00012\n",
      "Epoch 49/500\n",
      "74/74 [==============================] - 14s 189ms/step - loss: 2.6727e-04 - mean_absolute_error: 0.0126 - val_loss: 2.3991e-04 - val_mean_absolute_error: 0.0098\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00012\n",
      "Epoch 50/500\n",
      "74/74 [==============================] - 14s 189ms/step - loss: 3.7331e-04 - mean_absolute_error: 0.0144 - val_loss: 1.2373e-04 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00012\n",
      "Epoch 51/500\n",
      "74/74 [==============================] - 14s 189ms/step - loss: 2.3736e-04 - mean_absolute_error: 0.0122 - val_loss: 1.2030e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.00012\n",
      "Epoch 52/500\n",
      "74/74 [==============================] - 14s 189ms/step - loss: 2.5515e-04 - mean_absolute_error: 0.0124 - val_loss: 1.3206e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.00012\n",
      "Epoch 53/500\n",
      "74/74 [==============================] - 14s 186ms/step - loss: 2.5518e-04 - mean_absolute_error: 0.0123 - val_loss: 1.6604e-04 - val_mean_absolute_error: 0.0101\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.00012\n",
      "Epoch 54/500\n",
      "74/74 [==============================] - 14s 187ms/step - loss: 2.7535e-04 - mean_absolute_error: 0.0128 - val_loss: 1.2364e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00012\n",
      "Epoch 55/500\n",
      "74/74 [==============================] - 14s 187ms/step - loss: 2.1881e-04 - mean_absolute_error: 0.0117 - val_loss: 1.3691e-04 - val_mean_absolute_error: 0.0080\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.00012\n",
      "Epoch 56/500\n",
      "74/74 [==============================] - 14s 186ms/step - loss: 2.3995e-04 - mean_absolute_error: 0.0122 - val_loss: 1.1660e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.00012\n",
      "Epoch 57/500\n",
      "74/74 [==============================] - 13s 182ms/step - loss: 2.5818e-04 - mean_absolute_error: 0.0123 - val_loss: 1.8173e-04 - val_mean_absolute_error: 0.0089\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00012\n",
      "Epoch 58/500\n",
      "74/74 [==============================] - 14s 185ms/step - loss: 2.4784e-04 - mean_absolute_error: 0.0120 - val_loss: 1.2865e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00012\n",
      "Epoch 59/500\n",
      "74/74 [==============================] - 14s 188ms/step - loss: 2.1689e-04 - mean_absolute_error: 0.0117 - val_loss: 1.2150e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00012\n",
      "Epoch 60/500\n",
      "74/74 [==============================] - 14s 188ms/step - loss: 2.2568e-04 - mean_absolute_error: 0.0121 - val_loss: 1.1971e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.00012\n",
      "Epoch 61/500\n",
      "74/74 [==============================] - 14s 188ms/step - loss: 2.4004e-04 - mean_absolute_error: 0.0118 - val_loss: 1.1576e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00012 to 0.00012, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 62/500\n",
      "74/74 [==============================] - 14s 189ms/step - loss: 2.5013e-04 - mean_absolute_error: 0.0123 - val_loss: 2.4964e-04 - val_mean_absolute_error: 0.0125\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00012\n",
      "Epoch 63/500\n",
      "74/74 [==============================] - 14s 189ms/step - loss: 1.9260e-04 - mean_absolute_error: 0.0117 - val_loss: 3.1694e-04 - val_mean_absolute_error: 0.0124\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.00012\n",
      "Epoch 64/500\n",
      "74/74 [==============================] - 14s 189ms/step - loss: 2.6032e-04 - mean_absolute_error: 0.0125 - val_loss: 1.1628e-04 - val_mean_absolute_error: 0.0084\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.00012\n",
      "Epoch 65/500\n",
      "74/74 [==============================] - 14s 189ms/step - loss: 2.1050e-04 - mean_absolute_error: 0.0117 - val_loss: 1.4012e-04 - val_mean_absolute_error: 0.0088\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.00012\n",
      "Epoch 66/500\n",
      "74/74 [==============================] - 14s 188ms/step - loss: 2.3772e-04 - mean_absolute_error: 0.0120 - val_loss: 1.2029e-04 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.00012\n",
      "Epoch 67/500\n",
      "74/74 [==============================] - 14s 190ms/step - loss: 2.2848e-04 - mean_absolute_error: 0.0121 - val_loss: 1.1574e-04 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.00012 to 0.00012, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 68/500\n",
      "74/74 [==============================] - 15s 197ms/step - loss: 2.4143e-04 - mean_absolute_error: 0.0119 - val_loss: 1.2343e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.00012\n",
      "Epoch 69/500\n",
      "74/74 [==============================] - 14s 191ms/step - loss: 2.4742e-04 - mean_absolute_error: 0.0125 - val_loss: 1.1761e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.00012\n",
      "Epoch 70/500\n",
      "74/74 [==============================] - 14s 189ms/step - loss: 2.2651e-04 - mean_absolute_error: 0.0119 - val_loss: 1.2168e-04 - val_mean_absolute_error: 0.0084\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.00012\n",
      "Epoch 71/500\n",
      "74/74 [==============================] - 14s 190ms/step - loss: 1.9665e-04 - mean_absolute_error: 0.0112 - val_loss: 1.1461e-04 - val_mean_absolute_error: 0.0079\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.00012 to 0.00011, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 72/500\n",
      "74/74 [==============================] - 14s 190ms/step - loss: 2.4629e-04 - mean_absolute_error: 0.0123 - val_loss: 1.2279e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.00011\n",
      "Epoch 73/500\n",
      "74/74 [==============================] - 14s 190ms/step - loss: 2.5261e-04 - mean_absolute_error: 0.0127 - val_loss: 1.1848e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.00011\n",
      "Epoch 74/500\n",
      "74/74 [==============================] - 14s 190ms/step - loss: 2.3457e-04 - mean_absolute_error: 0.0122 - val_loss: 1.0905e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.00011 to 0.00011, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 75/500\n",
      "74/74 [==============================] - 14s 189ms/step - loss: 2.1944e-04 - mean_absolute_error: 0.0118 - val_loss: 1.2267e-04 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.00011\n",
      "Epoch 76/500\n",
      "74/74 [==============================] - 14s 189ms/step - loss: 2.1297e-04 - mean_absolute_error: 0.0114 - val_loss: 1.1872e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.00011\n",
      "Epoch 77/500\n",
      "74/74 [==============================] - 14s 189ms/step - loss: 2.1156e-04 - mean_absolute_error: 0.0118 - val_loss: 1.1565e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.00011\n",
      "Epoch 78/500\n",
      "74/74 [==============================] - 14s 190ms/step - loss: 2.1181e-04 - mean_absolute_error: 0.0118 - val_loss: 1.2423e-04 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.00011\n",
      "Epoch 79/500\n",
      "74/74 [==============================] - 14s 192ms/step - loss: 2.3826e-04 - mean_absolute_error: 0.0121 - val_loss: 1.4247e-04 - val_mean_absolute_error: 0.0088\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.00011\n",
      "Epoch 80/500\n",
      "74/74 [==============================] - 14s 195ms/step - loss: 2.0025e-04 - mean_absolute_error: 0.0114 - val_loss: 1.3983e-04 - val_mean_absolute_error: 0.0098\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.00011\n",
      "Epoch 81/500\n",
      "74/74 [==============================] - 14s 189ms/step - loss: 2.2634e-04 - mean_absolute_error: 0.0122 - val_loss: 1.1383e-04 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.00011\n",
      "Epoch 82/500\n",
      "74/74 [==============================] - 14s 190ms/step - loss: 2.2189e-04 - mean_absolute_error: 0.0118 - val_loss: 1.1846e-04 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.00011\n",
      "Epoch 83/500\n",
      "74/74 [==============================] - 14s 190ms/step - loss: 2.3401e-04 - mean_absolute_error: 0.0118 - val_loss: 1.0425e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.00011 to 0.00010, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 84/500\n",
      "74/74 [==============================] - 14s 195ms/step - loss: 1.9273e-04 - mean_absolute_error: 0.0113 - val_loss: 1.0265e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.00010 to 0.00010, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 85/500\n",
      "74/74 [==============================] - 15s 197ms/step - loss: 2.0082e-04 - mean_absolute_error: 0.0114 - val_loss: 1.6102e-04 - val_mean_absolute_error: 0.0079\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.00010\n",
      "Epoch 86/500\n",
      "74/74 [==============================] - 14s 193ms/step - loss: 3.2857e-04 - mean_absolute_error: 0.0136 - val_loss: 1.0321e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.00010\n",
      "Epoch 87/500\n",
      "74/74 [==============================] - 14s 189ms/step - loss: 1.9687e-04 - mean_absolute_error: 0.0115 - val_loss: 1.0930e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.00010\n",
      "Epoch 88/500\n",
      "74/74 [==============================] - 14s 189ms/step - loss: 2.1157e-04 - mean_absolute_error: 0.0120 - val_loss: 1.0713e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.00010\n",
      "Epoch 89/500\n",
      "74/74 [==============================] - 15s 207ms/step - loss: 2.0234e-04 - mean_absolute_error: 0.0115 - val_loss: 1.1064e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.00010\n",
      "Epoch 90/500\n",
      "74/74 [==============================] - 15s 202ms/step - loss: 2.3108e-04 - mean_absolute_error: 0.0121 - val_loss: 1.0070e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.00010 to 0.00010, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 91/500\n",
      "74/74 [==============================] - 15s 199ms/step - loss: 2.1303e-04 - mean_absolute_error: 0.0117 - val_loss: 9.6080e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.00010 to 0.00010, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 92/500\n",
      "74/74 [==============================] - 14s 195ms/step - loss: 2.1800e-04 - mean_absolute_error: 0.0118 - val_loss: 1.0787e-04 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.00010\n",
      "Epoch 93/500\n",
      "74/74 [==============================] - 15s 202ms/step - loss: 1.8884e-04 - mean_absolute_error: 0.0112 - val_loss: 1.1346e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.00010\n",
      "Epoch 94/500\n",
      "74/74 [==============================] - 15s 206ms/step - loss: 2.0447e-04 - mean_absolute_error: 0.0114 - val_loss: 1.1595e-04 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.00010\n",
      "Epoch 95/500\n",
      "74/74 [==============================] - 14s 196ms/step - loss: 2.1396e-04 - mean_absolute_error: 0.0117 - val_loss: 1.7049e-04 - val_mean_absolute_error: 0.0092\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.00010\n",
      "Epoch 96/500\n",
      "74/74 [==============================] - 14s 190ms/step - loss: 2.4768e-04 - mean_absolute_error: 0.0123 - val_loss: 1.0831e-04 - val_mean_absolute_error: 0.0079\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.00010\n",
      "Epoch 97/500\n",
      "74/74 [==============================] - 15s 204ms/step - loss: 2.2638e-04 - mean_absolute_error: 0.0120 - val_loss: 1.0152e-04 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.00010\n",
      "Epoch 98/500\n",
      "74/74 [==============================] - 15s 205ms/step - loss: 2.1698e-04 - mean_absolute_error: 0.0119 - val_loss: 1.3615e-04 - val_mean_absolute_error: 0.0087\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.00010\n",
      "Epoch 99/500\n",
      "74/74 [==============================] - 15s 202ms/step - loss: 2.3547e-04 - mean_absolute_error: 0.0124 - val_loss: 9.8723e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.00010\n",
      "Epoch 100/500\n",
      "74/74 [==============================] - 15s 197ms/step - loss: 1.8455e-04 - mean_absolute_error: 0.0113 - val_loss: 1.0841e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.00010\n",
      "Epoch 101/500\n",
      "74/74 [==============================] - 15s 208ms/step - loss: 2.3788e-04 - mean_absolute_error: 0.0123 - val_loss: 9.8388e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.00010\n",
      "Epoch 102/500\n",
      "74/74 [==============================] - 16s 213ms/step - loss: 2.0163e-04 - mean_absolute_error: 0.0116 - val_loss: 1.2127e-04 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.00010\n",
      "Epoch 103/500\n",
      "74/74 [==============================] - 16s 215ms/step - loss: 1.9497e-04 - mean_absolute_error: 0.0114 - val_loss: 1.0133e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.00010\n",
      "Epoch 104/500\n",
      "74/74 [==============================] - 15s 206ms/step - loss: 1.9852e-04 - mean_absolute_error: 0.0113 - val_loss: 1.1601e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.00010\n",
      "Epoch 105/500\n",
      "74/74 [==============================] - 15s 199ms/step - loss: 2.3098e-04 - mean_absolute_error: 0.0121 - val_loss: 1.1411e-04 - val_mean_absolute_error: 0.0085\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.00010\n",
      "Epoch 106/500\n",
      "74/74 [==============================] - 15s 196ms/step - loss: 2.2534e-04 - mean_absolute_error: 0.0121 - val_loss: 9.8588e-05 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.00010\n",
      "Epoch 107/500\n",
      "74/74 [==============================] - 15s 202ms/step - loss: 1.8733e-04 - mean_absolute_error: 0.0111 - val_loss: 1.2635e-04 - val_mean_absolute_error: 0.0081\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.00010\n",
      "Epoch 108/500\n",
      "74/74 [==============================] - 15s 201ms/step - loss: 1.8648e-04 - mean_absolute_error: 0.0112 - val_loss: 1.0374e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.00010\n",
      "Epoch 109/500\n",
      "74/74 [==============================] - 15s 203ms/step - loss: 2.1467e-04 - mean_absolute_error: 0.0115 - val_loss: 9.9118e-05 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.00010\n",
      "Epoch 110/500\n",
      "74/74 [==============================] - 14s 195ms/step - loss: 2.1105e-04 - mean_absolute_error: 0.0114 - val_loss: 1.0154e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.00010\n",
      "Epoch 111/500\n",
      "74/74 [==============================] - 15s 197ms/step - loss: 2.1481e-04 - mean_absolute_error: 0.0116 - val_loss: 1.0035e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.00010\n",
      "Epoch 112/500\n",
      "74/74 [==============================] - 15s 198ms/step - loss: 2.0777e-04 - mean_absolute_error: 0.0119 - val_loss: 1.0962e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.00010\n",
      "Epoch 113/500\n",
      "74/74 [==============================] - 15s 201ms/step - loss: 2.1771e-04 - mean_absolute_error: 0.0117 - val_loss: 1.0248e-04 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.00010\n",
      "Epoch 114/500\n",
      "74/74 [==============================] - 15s 198ms/step - loss: 2.5669e-04 - mean_absolute_error: 0.0126 - val_loss: 1.1820e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.00010\n",
      "Epoch 115/500\n",
      "74/74 [==============================] - 14s 193ms/step - loss: 1.8339e-04 - mean_absolute_error: 0.0113 - val_loss: 1.0567e-04 - val_mean_absolute_error: 0.0085\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.00010\n",
      "Epoch 116/500\n",
      "74/74 [==============================] - 14s 194ms/step - loss: 2.0540e-04 - mean_absolute_error: 0.0117 - val_loss: 1.3589e-04 - val_mean_absolute_error: 0.0084\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.00010\n",
      "Epoch 117/500\n",
      "74/74 [==============================] - 14s 194ms/step - loss: 2.0068e-04 - mean_absolute_error: 0.0114 - val_loss: 1.1216e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.00010\n",
      "Epoch 118/500\n",
      "74/74 [==============================] - 14s 193ms/step - loss: 1.8577e-04 - mean_absolute_error: 0.0113 - val_loss: 1.0064e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.00010\n",
      "Epoch 119/500\n",
      "74/74 [==============================] - 14s 194ms/step - loss: 2.0068e-04 - mean_absolute_error: 0.0114 - val_loss: 1.6279e-04 - val_mean_absolute_error: 0.0096\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.00010\n",
      "Epoch 120/500\n",
      "74/74 [==============================] - 14s 193ms/step - loss: 2.2045e-04 - mean_absolute_error: 0.0119 - val_loss: 1.1069e-04 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.00010\n",
      "Epoch 121/500\n",
      "74/74 [==============================] - 14s 194ms/step - loss: 1.9032e-04 - mean_absolute_error: 0.0109 - val_loss: 1.9177e-04 - val_mean_absolute_error: 0.0112\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.00010\n",
      "Epoch 122/500\n",
      "74/74 [==============================] - 14s 195ms/step - loss: 2.4097e-04 - mean_absolute_error: 0.0125 - val_loss: 1.1095e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.00010\n",
      "Epoch 123/500\n",
      "74/74 [==============================] - 15s 200ms/step - loss: 2.2918e-04 - mean_absolute_error: 0.0121 - val_loss: 1.0356e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.00010\n",
      "Epoch 124/500\n",
      "74/74 [==============================] - 14s 194ms/step - loss: 1.9672e-04 - mean_absolute_error: 0.0114 - val_loss: 1.1303e-04 - val_mean_absolute_error: 0.0085\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.00010\n",
      "Epoch 125/500\n",
      "74/74 [==============================] - 14s 193ms/step - loss: 2.0366e-04 - mean_absolute_error: 0.0114 - val_loss: 9.5003e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.00010 to 0.00010, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 126/500\n",
      "74/74 [==============================] - 14s 193ms/step - loss: 1.8702e-04 - mean_absolute_error: 0.0112 - val_loss: 1.1912e-04 - val_mean_absolute_error: 0.0081\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.00010\n",
      "Epoch 127/500\n",
      "74/74 [==============================] - 15s 198ms/step - loss: 1.8213e-04 - mean_absolute_error: 0.0109 - val_loss: 1.0192e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.00010\n",
      "Epoch 128/500\n",
      "74/74 [==============================] - 14s 195ms/step - loss: 1.7580e-04 - mean_absolute_error: 0.0108 - val_loss: 1.1247e-04 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.00010\n",
      "Epoch 129/500\n",
      "74/74 [==============================] - 14s 192ms/step - loss: 2.0960e-04 - mean_absolute_error: 0.0119 - val_loss: 1.1929e-04 - val_mean_absolute_error: 0.0083\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.00010\n",
      "Epoch 130/500\n",
      "74/74 [==============================] - 15s 203ms/step - loss: 2.0769e-04 - mean_absolute_error: 0.0115 - val_loss: 9.9682e-05 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.00010\n",
      "Epoch 131/500\n",
      "74/74 [==============================] - 15s 204ms/step - loss: 1.9465e-04 - mean_absolute_error: 0.0112 - val_loss: 9.7542e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.00010\n",
      "Epoch 132/500\n",
      "74/74 [==============================] - 14s 192ms/step - loss: 1.9983e-04 - mean_absolute_error: 0.0114 - val_loss: 9.8376e-05 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.00010\n",
      "Epoch 133/500\n",
      "74/74 [==============================] - 14s 187ms/step - loss: 1.9647e-04 - mean_absolute_error: 0.0112 - val_loss: 1.0661e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.00010\n",
      "Epoch 134/500\n",
      "74/74 [==============================] - 14s 184ms/step - loss: 1.9888e-04 - mean_absolute_error: 0.0114 - val_loss: 9.8713e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.00010\n",
      "Epoch 135/500\n",
      "74/74 [==============================] - 14s 187ms/step - loss: 1.8789e-04 - mean_absolute_error: 0.0110 - val_loss: 1.0654e-04 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.00010\n",
      "Epoch 136/500\n",
      "74/74 [==============================] - 14s 188ms/step - loss: 1.9015e-04 - mean_absolute_error: 0.0109 - val_loss: 1.6347e-04 - val_mean_absolute_error: 0.0079\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.00010\n",
      "Epoch 137/500\n",
      "74/74 [==============================] - 13s 179ms/step - loss: 2.4560e-04 - mean_absolute_error: 0.0124 - val_loss: 9.7097e-05 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.00010\n",
      "Epoch 138/500\n",
      "74/74 [==============================] - 13s 180ms/step - loss: 2.0328e-04 - mean_absolute_error: 0.0113 - val_loss: 1.2622e-04 - val_mean_absolute_error: 0.0096\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.00010\n",
      "Epoch 139/500\n",
      "74/74 [==============================] - 13s 179ms/step - loss: 2.0587e-04 - mean_absolute_error: 0.0118 - val_loss: 1.0789e-04 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.00010\n",
      "Epoch 140/500\n",
      "74/74 [==============================] - 13s 179ms/step - loss: 2.0891e-04 - mean_absolute_error: 0.0115 - val_loss: 1.0444e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.00010\n",
      "Epoch 141/500\n",
      "74/74 [==============================] - 13s 177ms/step - loss: 2.2000e-04 - mean_absolute_error: 0.0117 - val_loss: 1.0493e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.00010\n",
      "Epoch 142/500\n",
      "74/74 [==============================] - 13s 176ms/step - loss: 2.2448e-04 - mean_absolute_error: 0.0117 - val_loss: 9.5398e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.00010\n",
      "Epoch 143/500\n",
      "74/74 [==============================] - 13s 180ms/step - loss: 2.2394e-04 - mean_absolute_error: 0.0119 - val_loss: 1.0234e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.00010\n",
      "Epoch 144/500\n",
      "74/74 [==============================] - 13s 181ms/step - loss: 2.0324e-04 - mean_absolute_error: 0.0114 - val_loss: 9.8177e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.00010\n",
      "Epoch 145/500\n",
      "74/74 [==============================] - 13s 176ms/step - loss: 2.0866e-04 - mean_absolute_error: 0.0116 - val_loss: 1.0801e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.00010\n",
      "Epoch 146/500\n",
      "74/74 [==============================] - 13s 176ms/step - loss: 1.9458e-04 - mean_absolute_error: 0.0113 - val_loss: 1.1205e-04 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.00010\n",
      "Epoch 147/500\n",
      "74/74 [==============================] - 13s 176ms/step - loss: 2.2847e-04 - mean_absolute_error: 0.0117 - val_loss: 1.0868e-04 - val_mean_absolute_error: 0.0083\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.00010\n",
      "Epoch 148/500\n",
      "74/74 [==============================] - 13s 175ms/step - loss: 1.9381e-04 - mean_absolute_error: 0.0114 - val_loss: 9.6739e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.00010\n",
      "Epoch 149/500\n",
      "74/74 [==============================] - 13s 176ms/step - loss: 2.0669e-04 - mean_absolute_error: 0.0115 - val_loss: 9.6175e-05 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.00010\n",
      "Epoch 150/500\n",
      "74/74 [==============================] - 13s 177ms/step - loss: 1.7758e-04 - mean_absolute_error: 0.0110 - val_loss: 1.0676e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.00010\n",
      "Epoch 151/500\n",
      "74/74 [==============================] - 13s 176ms/step - loss: 2.1431e-04 - mean_absolute_error: 0.0115 - val_loss: 9.7527e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.00010\n",
      "Epoch 152/500\n",
      "74/74 [==============================] - 13s 176ms/step - loss: 2.0537e-04 - mean_absolute_error: 0.0115 - val_loss: 1.0196e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.00010\n",
      "Epoch 153/500\n",
      "74/74 [==============================] - 13s 176ms/step - loss: 2.2837e-04 - mean_absolute_error: 0.0117 - val_loss: 1.0357e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.00010\n",
      "Epoch 154/500\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 1.6212e-04 - mean_absolute_error: 0.0105 - val_loss: 1.2333e-04 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.00010\n",
      "Epoch 155/500\n",
      "74/74 [==============================] - 13s 175ms/step - loss: 1.7423e-04 - mean_absolute_error: 0.0104 - val_loss: 1.0596e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.00010\n",
      "Epoch 156/500\n",
      "74/74 [==============================] - 13s 176ms/step - loss: 1.9293e-04 - mean_absolute_error: 0.0112 - val_loss: 1.1163e-04 - val_mean_absolute_error: 0.0081\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.00010\n",
      "Epoch 157/500\n",
      "74/74 [==============================] - 13s 177ms/step - loss: 1.8903e-04 - mean_absolute_error: 0.0111 - val_loss: 1.0991e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.00010\n",
      "Epoch 158/500\n",
      "74/74 [==============================] - 13s 176ms/step - loss: 1.7710e-04 - mean_absolute_error: 0.0109 - val_loss: 1.1646e-04 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.00010\n",
      "Epoch 159/500\n",
      "74/74 [==============================] - 13s 176ms/step - loss: 2.1774e-04 - mean_absolute_error: 0.0119 - val_loss: 1.1364e-04 - val_mean_absolute_error: 0.0080\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.00010\n",
      "Epoch 160/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 2.0150e-04 - mean_absolute_error: 0.0111 - val_loss: 1.0964e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.00010\n",
      "Epoch 161/500\n",
      "74/74 [==============================] - 13s 175ms/step - loss: 1.8438e-04 - mean_absolute_error: 0.0108 - val_loss: 1.0039e-04 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.00010\n",
      "Epoch 162/500\n",
      "74/74 [==============================] - 13s 176ms/step - loss: 2.0858e-04 - mean_absolute_error: 0.0115 - val_loss: 9.7633e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.00010\n",
      "Epoch 163/500\n",
      "74/74 [==============================] - 13s 176ms/step - loss: 1.6976e-04 - mean_absolute_error: 0.0107 - val_loss: 1.0137e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.00010\n",
      "Epoch 164/500\n",
      "74/74 [==============================] - 13s 175ms/step - loss: 1.7889e-04 - mean_absolute_error: 0.0110 - val_loss: 9.4054e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.00010 to 0.00009, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 165/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 2.4301e-04 - mean_absolute_error: 0.0124 - val_loss: 1.0413e-04 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.00009\n",
      "Epoch 166/500\n",
      "74/74 [==============================] - 13s 174ms/step - loss: 2.2674e-04 - mean_absolute_error: 0.0119 - val_loss: 1.1339e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.00009\n",
      "Epoch 167/500\n",
      "74/74 [==============================] - 13s 175ms/step - loss: 1.8445e-04 - mean_absolute_error: 0.0110 - val_loss: 9.5635e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.00009\n",
      "Epoch 168/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.7326e-04 - mean_absolute_error: 0.0107 - val_loss: 1.0720e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.00009\n",
      "Epoch 169/500\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 2.0791e-04 - mean_absolute_error: 0.0115 - val_loss: 9.2370e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.00009 to 0.00009, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 170/500\n",
      "74/74 [==============================] - 13s 175ms/step - loss: 1.8020e-04 - mean_absolute_error: 0.0106 - val_loss: 1.1690e-04 - val_mean_absolute_error: 0.0088\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.00009\n",
      "Epoch 171/500\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 1.9663e-04 - mean_absolute_error: 0.0113 - val_loss: 9.4771e-05 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.00009\n",
      "Epoch 172/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.9574e-04 - mean_absolute_error: 0.0115 - val_loss: 1.3355e-04 - val_mean_absolute_error: 0.0081\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.00009\n",
      "Epoch 173/500\n",
      "74/74 [==============================] - 13s 174ms/step - loss: 2.2208e-04 - mean_absolute_error: 0.0119 - val_loss: 1.1594e-04 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.00009\n",
      "Epoch 174/500\n",
      "74/74 [==============================] - 13s 175ms/step - loss: 2.2141e-04 - mean_absolute_error: 0.0118 - val_loss: 9.5745e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.00009\n",
      "Epoch 175/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.9112e-04 - mean_absolute_error: 0.0112 - val_loss: 1.0870e-04 - val_mean_absolute_error: 0.0080\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.00009\n",
      "Epoch 176/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.8643e-04 - mean_absolute_error: 0.0111 - val_loss: 1.4306e-04 - val_mean_absolute_error: 0.0081\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.00009\n",
      "Epoch 177/500\n",
      "74/74 [==============================] - 13s 174ms/step - loss: 1.8067e-04 - mean_absolute_error: 0.0110 - val_loss: 1.0978e-04 - val_mean_absolute_error: 0.0089\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.00009\n",
      "Epoch 178/500\n",
      "74/74 [==============================] - 13s 177ms/step - loss: 2.0283e-04 - mean_absolute_error: 0.0114 - val_loss: 1.0478e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.00009\n",
      "Epoch 179/500\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 1.9932e-04 - mean_absolute_error: 0.0112 - val_loss: 9.7868e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.00009\n",
      "Epoch 180/500\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 1.7767e-04 - mean_absolute_error: 0.0108 - val_loss: 9.6851e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.00009\n",
      "Epoch 181/500\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 1.6813e-04 - mean_absolute_error: 0.0106 - val_loss: 1.1947e-04 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.00009\n",
      "Epoch 182/500\n",
      "74/74 [==============================] - 13s 173ms/step - loss: 2.0206e-04 - mean_absolute_error: 0.0115 - val_loss: 9.4289e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.00009\n",
      "Epoch 183/500\n",
      "74/74 [==============================] - 13s 174ms/step - loss: 1.8449e-04 - mean_absolute_error: 0.0111 - val_loss: 1.0398e-04 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.00009\n",
      "Epoch 184/500\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 2.1992e-04 - mean_absolute_error: 0.0115 - val_loss: 9.5853e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.00009\n",
      "Epoch 185/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.9071e-04 - mean_absolute_error: 0.0108 - val_loss: 1.2422e-04 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.00009\n",
      "Epoch 186/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 2.2667e-04 - mean_absolute_error: 0.0119 - val_loss: 9.1853e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.00009 to 0.00009, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 187/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 2.0216e-04 - mean_absolute_error: 0.0113 - val_loss: 1.0704e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.00009\n",
      "Epoch 188/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.9316e-04 - mean_absolute_error: 0.0112 - val_loss: 9.8881e-05 - val_mean_absolute_error: 0.0079\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.00009\n",
      "Epoch 189/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 2.0564e-04 - mean_absolute_error: 0.0115 - val_loss: 9.7091e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.00009\n",
      "Epoch 190/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.9030e-04 - mean_absolute_error: 0.0109 - val_loss: 1.0247e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.00009\n",
      "Epoch 191/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.8239e-04 - mean_absolute_error: 0.0109 - val_loss: 9.2481e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.00009\n",
      "Epoch 192/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.7982e-04 - mean_absolute_error: 0.0110 - val_loss: 9.6507e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.00009\n",
      "Epoch 193/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.7146e-04 - mean_absolute_error: 0.0107 - val_loss: 9.1122e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.00009 to 0.00009, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 194/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.8961e-04 - mean_absolute_error: 0.0108 - val_loss: 1.4594e-04 - val_mean_absolute_error: 0.0086\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.00009\n",
      "Epoch 195/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.6909e-04 - mean_absolute_error: 0.0109 - val_loss: 1.1696e-04 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.00009\n",
      "Epoch 196/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 2.1876e-04 - mean_absolute_error: 0.0117 - val_loss: 9.1617e-05 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.00009\n",
      "Epoch 197/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.8393e-04 - mean_absolute_error: 0.0106 - val_loss: 9.7644e-05 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.00009\n",
      "Epoch 198/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.7646e-04 - mean_absolute_error: 0.0109 - val_loss: 1.1790e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.00009\n",
      "Epoch 199/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 2.0216e-04 - mean_absolute_error: 0.0115 - val_loss: 1.7604e-04 - val_mean_absolute_error: 0.0098\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.00009\n",
      "Epoch 200/500\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 2.2427e-04 - mean_absolute_error: 0.0120 - val_loss: 1.1791e-04 - val_mean_absolute_error: 0.0088\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.00009\n",
      "Epoch 201/500\n",
      "74/74 [==============================] - 13s 173ms/step - loss: 1.9333e-04 - mean_absolute_error: 0.0113 - val_loss: 1.0550e-04 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.00009\n",
      "Epoch 202/500\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 1.9657e-04 - mean_absolute_error: 0.0112 - val_loss: 1.1620e-04 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.00009\n",
      "Epoch 203/500\n",
      "74/74 [==============================] - 13s 174ms/step - loss: 1.8699e-04 - mean_absolute_error: 0.0109 - val_loss: 1.2075e-04 - val_mean_absolute_error: 0.0083\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.00009\n",
      "Epoch 204/500\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 2.0321e-04 - mean_absolute_error: 0.0113 - val_loss: 1.2718e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.00009\n",
      "Epoch 205/500\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 2.1412e-04 - mean_absolute_error: 0.0111 - val_loss: 9.7854e-05 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.00009\n",
      "Epoch 206/500\n",
      "74/74 [==============================] - 13s 173ms/step - loss: 1.7766e-04 - mean_absolute_error: 0.0107 - val_loss: 8.9857e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00206: val_loss improved from 0.00009 to 0.00009, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 207/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.6993e-04 - mean_absolute_error: 0.0104 - val_loss: 9.1969e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.00009\n",
      "Epoch 208/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.9146e-04 - mean_absolute_error: 0.0109 - val_loss: 1.0715e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.00009\n",
      "Epoch 209/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.8085e-04 - mean_absolute_error: 0.0108 - val_loss: 9.4828e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.00009\n",
      "Epoch 210/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.8736e-04 - mean_absolute_error: 0.0113 - val_loss: 1.2843e-04 - val_mean_absolute_error: 0.0085\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.00009\n",
      "Epoch 211/500\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 2.0946e-04 - mean_absolute_error: 0.0115 - val_loss: 9.8200e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.00009\n",
      "Epoch 212/500\n",
      "74/74 [==============================] - 12s 166ms/step - loss: 1.7777e-04 - mean_absolute_error: 0.0109 - val_loss: 1.3824e-04 - val_mean_absolute_error: 0.0093\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.00009\n",
      "Epoch 213/500\n",
      "74/74 [==============================] - 12s 167ms/step - loss: 1.9605e-04 - mean_absolute_error: 0.0111 - val_loss: 9.3900e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.00009\n",
      "Epoch 214/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 2.0837e-04 - mean_absolute_error: 0.0109 - val_loss: 1.0383e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.00009\n",
      "Epoch 215/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.7378e-04 - mean_absolute_error: 0.0106 - val_loss: 1.0162e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.00009\n",
      "Epoch 216/500\n",
      "74/74 [==============================] - 12s 166ms/step - loss: 1.7796e-04 - mean_absolute_error: 0.0107 - val_loss: 9.9560e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.00009\n",
      "Epoch 217/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.7648e-04 - mean_absolute_error: 0.0107 - val_loss: 1.0485e-04 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.00009\n",
      "Epoch 218/500\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 1.8277e-04 - mean_absolute_error: 0.0107 - val_loss: 9.1734e-05 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.00009\n",
      "Epoch 219/500\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 1.8412e-04 - mean_absolute_error: 0.0109 - val_loss: 1.2965e-04 - val_mean_absolute_error: 0.0080\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.00009\n",
      "Epoch 220/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.8145e-04 - mean_absolute_error: 0.0106 - val_loss: 1.1329e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.00009\n",
      "Epoch 221/500\n",
      "74/74 [==============================] - 12s 167ms/step - loss: 1.9319e-04 - mean_absolute_error: 0.0109 - val_loss: 9.5856e-05 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.00009\n",
      "Epoch 222/500\n",
      "74/74 [==============================] - 12s 165ms/step - loss: 2.1791e-04 - mean_absolute_error: 0.0117 - val_loss: 1.2894e-04 - val_mean_absolute_error: 0.0087\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.00009\n",
      "Epoch 223/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.9664e-04 - mean_absolute_error: 0.0112 - val_loss: 1.1571e-04 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.00009\n",
      "Epoch 224/500\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 1.9790e-04 - mean_absolute_error: 0.0113 - val_loss: 9.6512e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.00009\n",
      "Epoch 225/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.7290e-04 - mean_absolute_error: 0.0108 - val_loss: 9.5435e-05 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.00009\n",
      "Epoch 226/500\n",
      "74/74 [==============================] - 12s 166ms/step - loss: 1.9120e-04 - mean_absolute_error: 0.0109 - val_loss: 1.1732e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.00009\n",
      "Epoch 227/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.7972e-04 - mean_absolute_error: 0.0107 - val_loss: 9.4086e-05 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.00009\n",
      "Epoch 228/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 2.0071e-04 - mean_absolute_error: 0.0107 - val_loss: 1.0265e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.00009\n",
      "Epoch 229/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.7028e-04 - mean_absolute_error: 0.0105 - val_loss: 1.0199e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.00009\n",
      "Epoch 230/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.8682e-04 - mean_absolute_error: 0.0112 - val_loss: 8.9759e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00230: val_loss improved from 0.00009 to 0.00009, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 231/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.6657e-04 - mean_absolute_error: 0.0106 - val_loss: 1.1779e-04 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.00009\n",
      "Epoch 232/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.7855e-04 - mean_absolute_error: 0.0107 - val_loss: 8.9113e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00232: val_loss improved from 0.00009 to 0.00009, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 233/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.8131e-04 - mean_absolute_error: 0.0109 - val_loss: 1.0919e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.00009\n",
      "Epoch 234/500\n",
      "74/74 [==============================] - 12s 167ms/step - loss: 2.0703e-04 - mean_absolute_error: 0.0113 - val_loss: 1.2640e-04 - val_mean_absolute_error: 0.0090\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.00009\n",
      "Epoch 235/500\n",
      "74/74 [==============================] - 12s 167ms/step - loss: 1.9141e-04 - mean_absolute_error: 0.0110 - val_loss: 9.1001e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.00009\n",
      "Epoch 236/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.8437e-04 - mean_absolute_error: 0.0107 - val_loss: 9.0759e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.00009\n",
      "Epoch 237/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.9944e-04 - mean_absolute_error: 0.0114 - val_loss: 9.6482e-05 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.00009\n",
      "Epoch 238/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.7783e-04 - mean_absolute_error: 0.0104 - val_loss: 1.0335e-04 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.00009\n",
      "Epoch 239/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.8919e-04 - mean_absolute_error: 0.0108 - val_loss: 9.6894e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.00009\n",
      "Epoch 240/500\n",
      "74/74 [==============================] - 12s 167ms/step - loss: 1.8724e-04 - mean_absolute_error: 0.0106 - val_loss: 8.7078e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00240: val_loss improved from 0.00009 to 0.00009, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 241/500\n",
      "74/74 [==============================] - 12s 167ms/step - loss: 1.8081e-04 - mean_absolute_error: 0.0107 - val_loss: 1.1331e-04 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.00009\n",
      "Epoch 242/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.8085e-04 - mean_absolute_error: 0.0108 - val_loss: 9.3141e-05 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.00009\n",
      "Epoch 243/500\n",
      "74/74 [==============================] - 12s 166ms/step - loss: 1.7228e-04 - mean_absolute_error: 0.0107 - val_loss: 1.1415e-04 - val_mean_absolute_error: 0.0080\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.00009\n",
      "Epoch 244/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.9387e-04 - mean_absolute_error: 0.0110 - val_loss: 9.1518e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.00009\n",
      "Epoch 245/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.7409e-04 - mean_absolute_error: 0.0105 - val_loss: 9.1997e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.00009\n",
      "Epoch 246/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.6823e-04 - mean_absolute_error: 0.0104 - val_loss: 1.0534e-04 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.00009\n",
      "Epoch 247/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.8566e-04 - mean_absolute_error: 0.0107 - val_loss: 9.6438e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.00009\n",
      "Epoch 248/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.7251e-04 - mean_absolute_error: 0.0105 - val_loss: 9.1363e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.00009\n",
      "Epoch 249/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.8414e-04 - mean_absolute_error: 0.0104 - val_loss: 1.2484e-04 - val_mean_absolute_error: 0.0081\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.00009\n",
      "Epoch 250/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.7667e-04 - mean_absolute_error: 0.0105 - val_loss: 1.2351e-04 - val_mean_absolute_error: 0.0085\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.00009\n",
      "Epoch 251/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 2.1599e-04 - mean_absolute_error: 0.0114 - val_loss: 1.0922e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.00009\n",
      "Epoch 252/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.9838e-04 - mean_absolute_error: 0.0110 - val_loss: 9.5420e-05 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.00009\n",
      "Epoch 253/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.7705e-04 - mean_absolute_error: 0.0106 - val_loss: 8.7931e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.00009\n",
      "Epoch 254/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.8777e-04 - mean_absolute_error: 0.0105 - val_loss: 9.0528e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.00009\n",
      "Epoch 255/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.9040e-04 - mean_absolute_error: 0.0107 - val_loss: 1.0609e-04 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.00009\n",
      "Epoch 256/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.8461e-04 - mean_absolute_error: 0.0109 - val_loss: 1.0546e-04 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.00009\n",
      "Epoch 257/500\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 1.6772e-04 - mean_absolute_error: 0.0104 - val_loss: 1.2467e-04 - val_mean_absolute_error: 0.0081\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.00009\n",
      "Epoch 258/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.7723e-04 - mean_absolute_error: 0.0105 - val_loss: 9.0633e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.00009\n",
      "Epoch 259/500\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 1.7679e-04 - mean_absolute_error: 0.0106 - val_loss: 8.4859e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00259: val_loss improved from 0.00009 to 0.00008, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 260/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.6258e-04 - mean_absolute_error: 0.0104 - val_loss: 1.2384e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.00008\n",
      "Epoch 261/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.7901e-04 - mean_absolute_error: 0.0105 - val_loss: 1.2559e-04 - val_mean_absolute_error: 0.0087\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.00008\n",
      "Epoch 262/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.9027e-04 - mean_absolute_error: 0.0109 - val_loss: 1.0113e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.00008\n",
      "Epoch 263/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.6741e-04 - mean_absolute_error: 0.0103 - val_loss: 8.5718e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.00008\n",
      "Epoch 264/500\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 1.8721e-04 - mean_absolute_error: 0.0110 - val_loss: 1.0104e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.00008\n",
      "Epoch 265/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 2.2946e-04 - mean_absolute_error: 0.0116 - val_loss: 1.2117e-04 - val_mean_absolute_error: 0.0081\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.00008\n",
      "Epoch 266/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 2.0396e-04 - mean_absolute_error: 0.0109 - val_loss: 8.9113e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.00008\n",
      "Epoch 267/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.9110e-04 - mean_absolute_error: 0.0109 - val_loss: 1.0156e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.00008\n",
      "Epoch 268/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 2.0149e-04 - mean_absolute_error: 0.0112 - val_loss: 1.0884e-04 - val_mean_absolute_error: 0.0082\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.00008\n",
      "Epoch 269/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.6397e-04 - mean_absolute_error: 0.0105 - val_loss: 8.7401e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.00008\n",
      "Epoch 270/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.8678e-04 - mean_absolute_error: 0.0107 - val_loss: 1.1578e-04 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.00008\n",
      "Epoch 271/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.9042e-04 - mean_absolute_error: 0.0109 - val_loss: 8.7569e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.00008\n",
      "Epoch 272/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.7923e-04 - mean_absolute_error: 0.0109 - val_loss: 8.9318e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.00008\n",
      "Epoch 273/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.6353e-04 - mean_absolute_error: 0.0102 - val_loss: 8.5354e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.00008\n",
      "Epoch 274/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.9286e-04 - mean_absolute_error: 0.0108 - val_loss: 1.0081e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.00008\n",
      "Epoch 275/500\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 1.7695e-04 - mean_absolute_error: 0.0107 - val_loss: 8.6245e-05 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.00008\n",
      "Epoch 276/500\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 1.7425e-04 - mean_absolute_error: 0.0105 - val_loss: 8.5807e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.00008\n",
      "Epoch 277/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.7225e-04 - mean_absolute_error: 0.0104 - val_loss: 1.0452e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.00008\n",
      "Epoch 278/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.9410e-04 - mean_absolute_error: 0.0108 - val_loss: 8.7112e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.00008\n",
      "Epoch 279/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.8240e-04 - mean_absolute_error: 0.0108 - val_loss: 9.1864e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.00008\n",
      "Epoch 280/500\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 1.9627e-04 - mean_absolute_error: 0.0112 - val_loss: 8.8574e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.00008\n",
      "Epoch 281/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.8022e-04 - mean_absolute_error: 0.0106 - val_loss: 9.5871e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.00008\n",
      "Epoch 282/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.9723e-04 - mean_absolute_error: 0.0109 - val_loss: 9.0145e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.00008\n",
      "Epoch 283/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.6761e-04 - mean_absolute_error: 0.0103 - val_loss: 8.3965e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00283: val_loss improved from 0.00008 to 0.00008, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 284/500\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 1.7682e-04 - mean_absolute_error: 0.0104 - val_loss: 9.2555e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.00008\n",
      "Epoch 285/500\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 1.8594e-04 - mean_absolute_error: 0.0110 - val_loss: 1.2184e-04 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.00008\n",
      "Epoch 286/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.8796e-04 - mean_absolute_error: 0.0113 - val_loss: 9.5987e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.00008\n",
      "Epoch 287/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 2.1653e-04 - mean_absolute_error: 0.0112 - val_loss: 9.3057e-05 - val_mean_absolute_error: 0.0079\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.00008\n",
      "Epoch 288/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.8283e-04 - mean_absolute_error: 0.0109 - val_loss: 8.3438e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00288: val_loss improved from 0.00008 to 0.00008, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 289/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.5242e-04 - mean_absolute_error: 0.0100 - val_loss: 8.1925e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00289: val_loss improved from 0.00008 to 0.00008, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 290/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.7087e-04 - mean_absolute_error: 0.0104 - val_loss: 1.0549e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.00008\n",
      "Epoch 291/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.9562e-04 - mean_absolute_error: 0.0111 - val_loss: 1.2438e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.00008\n",
      "Epoch 292/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.8955e-04 - mean_absolute_error: 0.0109 - val_loss: 7.9917e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00292: val_loss improved from 0.00008 to 0.00008, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 293/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.7948e-04 - mean_absolute_error: 0.0107 - val_loss: 1.2265e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.00008\n",
      "Epoch 294/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 2.2112e-04 - mean_absolute_error: 0.0115 - val_loss: 9.4694e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.00008\n",
      "Epoch 295/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.9853e-04 - mean_absolute_error: 0.0109 - val_loss: 9.6639e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.00008\n",
      "Epoch 296/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.8361e-04 - mean_absolute_error: 0.0108 - val_loss: 9.8388e-05 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.00008\n",
      "Epoch 297/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.7415e-04 - mean_absolute_error: 0.0108 - val_loss: 8.5777e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.00008\n",
      "Epoch 298/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.7890e-04 - mean_absolute_error: 0.0105 - val_loss: 8.7575e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.00008\n",
      "Epoch 299/500\n",
      "74/74 [==============================] - 13s 173ms/step - loss: 1.6224e-04 - mean_absolute_error: 0.0104 - val_loss: 8.6424e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.00008\n",
      "Epoch 300/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.6120e-04 - mean_absolute_error: 0.0102 - val_loss: 8.1000e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.00008\n",
      "Epoch 301/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.5636e-04 - mean_absolute_error: 0.0103 - val_loss: 1.0639e-04 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.00008\n",
      "Epoch 302/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.5914e-04 - mean_absolute_error: 0.0102 - val_loss: 1.1361e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.00008\n",
      "Epoch 303/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.7894e-04 - mean_absolute_error: 0.0106 - val_loss: 1.0272e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.00008\n",
      "Epoch 304/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.8374e-04 - mean_absolute_error: 0.0107 - val_loss: 8.9701e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.00008\n",
      "Epoch 305/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.6144e-04 - mean_absolute_error: 0.0104 - val_loss: 1.5375e-04 - val_mean_absolute_error: 0.0089\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.00008\n",
      "Epoch 306/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 2.1553e-04 - mean_absolute_error: 0.0113 - val_loss: 8.9261e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.00008\n",
      "Epoch 307/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.9281e-04 - mean_absolute_error: 0.0109 - val_loss: 1.0026e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.00008\n",
      "Epoch 308/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.5593e-04 - mean_absolute_error: 0.0102 - val_loss: 8.5619e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.00008\n",
      "Epoch 309/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.9006e-04 - mean_absolute_error: 0.0107 - val_loss: 1.0804e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.00008\n",
      "Epoch 310/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.8423e-04 - mean_absolute_error: 0.0106 - val_loss: 7.8274e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00310: val_loss improved from 0.00008 to 0.00008, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 311/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.7171e-04 - mean_absolute_error: 0.0103 - val_loss: 8.7765e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.00008\n",
      "Epoch 312/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.7584e-04 - mean_absolute_error: 0.0107 - val_loss: 1.5981e-04 - val_mean_absolute_error: 0.0082\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.00008\n",
      "Epoch 313/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.5600e-04 - mean_absolute_error: 0.0105 - val_loss: 8.2551e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.00008\n",
      "Epoch 314/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.7207e-04 - mean_absolute_error: 0.0104 - val_loss: 1.3795e-04 - val_mean_absolute_error: 0.0089\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.00008\n",
      "Epoch 315/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.8390e-04 - mean_absolute_error: 0.0110 - val_loss: 9.0392e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.00008\n",
      "Epoch 316/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.9002e-04 - mean_absolute_error: 0.0108 - val_loss: 8.7951e-05 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.00008\n",
      "Epoch 317/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.9283e-04 - mean_absolute_error: 0.0110 - val_loss: 8.1283e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.00008\n",
      "Epoch 318/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.4760e-04 - mean_absolute_error: 0.0100 - val_loss: 8.0631e-05 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.00008\n",
      "Epoch 319/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.8917e-04 - mean_absolute_error: 0.0109 - val_loss: 9.2542e-05 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.00008\n",
      "Epoch 320/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.8655e-04 - mean_absolute_error: 0.0109 - val_loss: 9.6999e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.00008\n",
      "Epoch 321/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.9886e-04 - mean_absolute_error: 0.0111 - val_loss: 9.2278e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.00008\n",
      "Epoch 322/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.7003e-04 - mean_absolute_error: 0.0103 - val_loss: 7.8647e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.00008\n",
      "Epoch 323/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.7824e-04 - mean_absolute_error: 0.0105 - val_loss: 8.2732e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.00008\n",
      "Epoch 324/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.6569e-04 - mean_absolute_error: 0.0104 - val_loss: 8.3720e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.00008\n",
      "Epoch 325/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.5824e-04 - mean_absolute_error: 0.0103 - val_loss: 7.5851e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00325: val_loss improved from 0.00008 to 0.00008, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 326/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.6003e-04 - mean_absolute_error: 0.0103 - val_loss: 8.3703e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.00008\n",
      "Epoch 327/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.8243e-04 - mean_absolute_error: 0.0106 - val_loss: 9.9591e-05 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.00008\n",
      "Epoch 328/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.6221e-04 - mean_absolute_error: 0.0101 - val_loss: 8.7842e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.00008\n",
      "Epoch 329/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.9021e-04 - mean_absolute_error: 0.0109 - val_loss: 9.4701e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.00008\n",
      "Epoch 330/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.7298e-04 - mean_absolute_error: 0.0103 - val_loss: 9.5085e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.00008\n",
      "Epoch 331/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.9053e-04 - mean_absolute_error: 0.0110 - val_loss: 9.6968e-05 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.00008\n",
      "Epoch 332/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.7034e-04 - mean_absolute_error: 0.0108 - val_loss: 1.5548e-04 - val_mean_absolute_error: 0.0092\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.00008\n",
      "Epoch 333/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 2.0020e-04 - mean_absolute_error: 0.0110 - val_loss: 1.0996e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.00008\n",
      "Epoch 334/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.8431e-04 - mean_absolute_error: 0.0106 - val_loss: 9.1332e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.00008\n",
      "Epoch 335/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.9178e-04 - mean_absolute_error: 0.0109 - val_loss: 9.0613e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.00008\n",
      "Epoch 336/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.5743e-04 - mean_absolute_error: 0.0101 - val_loss: 9.4776e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.00008\n",
      "Epoch 337/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.5993e-04 - mean_absolute_error: 0.0103 - val_loss: 9.7003e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.00008\n",
      "Epoch 338/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.5183e-04 - mean_absolute_error: 0.0098 - val_loss: 1.2250e-04 - val_mean_absolute_error: 0.0079\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.00008\n",
      "Epoch 339/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 2.0226e-04 - mean_absolute_error: 0.0110 - val_loss: 1.1675e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.00008\n",
      "Epoch 340/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.8729e-04 - mean_absolute_error: 0.0107 - val_loss: 9.5653e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.00008\n",
      "Epoch 341/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.6715e-04 - mean_absolute_error: 0.0103 - val_loss: 9.2398e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.00008\n",
      "Epoch 342/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.6296e-04 - mean_absolute_error: 0.0103 - val_loss: 8.5037e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.00008\n",
      "Epoch 343/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.6475e-04 - mean_absolute_error: 0.0104 - val_loss: 1.5035e-04 - val_mean_absolute_error: 0.0092\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.00008\n",
      "Epoch 344/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.8132e-04 - mean_absolute_error: 0.0108 - val_loss: 7.7585e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.00008\n",
      "Epoch 345/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.8618e-04 - mean_absolute_error: 0.0109 - val_loss: 8.1944e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.00008\n",
      "Epoch 346/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.3629e-04 - mean_absolute_error: 0.0097 - val_loss: 8.2144e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.00008\n",
      "Epoch 347/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.8041e-04 - mean_absolute_error: 0.0109 - val_loss: 7.9340e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.00008\n",
      "Epoch 348/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.9042e-04 - mean_absolute_error: 0.0110 - val_loss: 9.1850e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.00008\n",
      "Epoch 349/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.5003e-04 - mean_absolute_error: 0.0098 - val_loss: 1.0870e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.00008\n",
      "Epoch 350/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 2.0382e-04 - mean_absolute_error: 0.0113 - val_loss: 1.0612e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.00008\n",
      "Epoch 351/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.8634e-04 - mean_absolute_error: 0.0107 - val_loss: 9.3774e-05 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.00008\n",
      "Epoch 352/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.8548e-04 - mean_absolute_error: 0.0106 - val_loss: 7.7754e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.00008\n",
      "Epoch 353/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.6033e-04 - mean_absolute_error: 0.0101 - val_loss: 9.0637e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.00008\n",
      "Epoch 354/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 2.0726e-04 - mean_absolute_error: 0.0110 - val_loss: 7.8379e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.00008\n",
      "Epoch 355/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.8381e-04 - mean_absolute_error: 0.0103 - val_loss: 9.7059e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.00008\n",
      "Epoch 356/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.8060e-04 - mean_absolute_error: 0.0106 - val_loss: 9.4921e-05 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.00008\n",
      "Epoch 357/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.6156e-04 - mean_absolute_error: 0.0101 - val_loss: 8.3431e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.00008\n",
      "Epoch 358/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.8590e-04 - mean_absolute_error: 0.0106 - val_loss: 8.4390e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.00008\n",
      "Epoch 359/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.6377e-04 - mean_absolute_error: 0.0102 - val_loss: 1.3421e-04 - val_mean_absolute_error: 0.0083\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.00008\n",
      "Epoch 360/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.7265e-04 - mean_absolute_error: 0.0104 - val_loss: 8.4612e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.00008\n",
      "Epoch 361/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.7976e-04 - mean_absolute_error: 0.0106 - val_loss: 8.5248e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.00008\n",
      "Epoch 362/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.6239e-04 - mean_absolute_error: 0.0100 - val_loss: 8.1244e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.00008\n",
      "Epoch 363/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.5806e-04 - mean_absolute_error: 0.0100 - val_loss: 1.0582e-04 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.00008\n",
      "Epoch 364/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 2.1227e-04 - mean_absolute_error: 0.0112 - val_loss: 1.0357e-04 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.00008\n",
      "Epoch 365/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.8217e-04 - mean_absolute_error: 0.0108 - val_loss: 8.6753e-05 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.00008\n",
      "Epoch 366/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.6864e-04 - mean_absolute_error: 0.0103 - val_loss: 8.0707e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.00008\n",
      "Epoch 367/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 2.0106e-04 - mean_absolute_error: 0.0109 - val_loss: 8.4103e-05 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.00008\n",
      "Epoch 368/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.5871e-04 - mean_absolute_error: 0.0103 - val_loss: 8.8974e-05 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.00008\n",
      "Epoch 369/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.6913e-04 - mean_absolute_error: 0.0106 - val_loss: 8.1043e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.00008\n",
      "Epoch 370/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.6327e-04 - mean_absolute_error: 0.0103 - val_loss: 7.6613e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.00008\n",
      "Epoch 371/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.9612e-04 - mean_absolute_error: 0.0113 - val_loss: 1.2493e-04 - val_mean_absolute_error: 0.0082\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.00008\n",
      "Epoch 372/500\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 1.7701e-04 - mean_absolute_error: 0.0107 - val_loss: 7.9688e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.00008\n",
      "Epoch 373/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.6517e-04 - mean_absolute_error: 0.0102 - val_loss: 1.0031e-04 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.00008\n",
      "Epoch 374/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.7230e-04 - mean_absolute_error: 0.0102 - val_loss: 8.4883e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.00008\n",
      "Epoch 375/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.6796e-04 - mean_absolute_error: 0.0104 - val_loss: 9.6789e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.00008\n",
      "Epoch 376/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.5836e-04 - mean_absolute_error: 0.0102 - val_loss: 8.4656e-05 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.00008\n",
      "Epoch 377/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.7781e-04 - mean_absolute_error: 0.0106 - val_loss: 7.7978e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.00008\n",
      "Epoch 378/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.5594e-04 - mean_absolute_error: 0.0099 - val_loss: 7.9795e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.00008\n",
      "Epoch 379/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.7640e-04 - mean_absolute_error: 0.0105 - val_loss: 7.6491e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.00008\n",
      "Epoch 380/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.6116e-04 - mean_absolute_error: 0.0101 - val_loss: 9.2040e-05 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.00008\n",
      "Epoch 381/500\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 1.6436e-04 - mean_absolute_error: 0.0106 - val_loss: 1.0777e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.00008\n",
      "Epoch 382/500\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 1.6144e-04 - mean_absolute_error: 0.0103 - val_loss: 7.4066e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00382: val_loss improved from 0.00008 to 0.00007, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 383/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.7117e-04 - mean_absolute_error: 0.0106 - val_loss: 7.4629e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.00007\n",
      "Epoch 384/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.5746e-04 - mean_absolute_error: 0.0101 - val_loss: 1.3517e-04 - val_mean_absolute_error: 0.0087\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.00007\n",
      "Epoch 385/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.6942e-04 - mean_absolute_error: 0.0105 - val_loss: 7.2700e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00385: val_loss improved from 0.00007 to 0.00007, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 386/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.9168e-04 - mean_absolute_error: 0.0106 - val_loss: 8.1447e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.00007\n",
      "Epoch 387/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.6049e-04 - mean_absolute_error: 0.0102 - val_loss: 9.3613e-05 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.00007\n",
      "Epoch 388/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.7887e-04 - mean_absolute_error: 0.0106 - val_loss: 7.8199e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.00007\n",
      "Epoch 389/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.6697e-04 - mean_absolute_error: 0.0101 - val_loss: 7.7491e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.00007\n",
      "Epoch 390/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.4466e-04 - mean_absolute_error: 0.0098 - val_loss: 9.9041e-05 - val_mean_absolute_error: 0.0080\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.00007\n",
      "Epoch 391/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.7903e-04 - mean_absolute_error: 0.0107 - val_loss: 8.4817e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.00007\n",
      "Epoch 392/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.5226e-04 - mean_absolute_error: 0.0099 - val_loss: 1.3596e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.00007\n",
      "Epoch 393/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.7934e-04 - mean_absolute_error: 0.0107 - val_loss: 1.6613e-04 - val_mean_absolute_error: 0.0084\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.00007\n",
      "Epoch 394/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.8182e-04 - mean_absolute_error: 0.0107 - val_loss: 7.7222e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.00007\n",
      "Epoch 395/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.7550e-04 - mean_absolute_error: 0.0105 - val_loss: 1.0098e-04 - val_mean_absolute_error: 0.0081\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.00007\n",
      "Epoch 396/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.6037e-04 - mean_absolute_error: 0.0103 - val_loss: 7.5996e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.00007\n",
      "Epoch 397/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.5494e-04 - mean_absolute_error: 0.0101 - val_loss: 7.7315e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.00007\n",
      "Epoch 398/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.5534e-04 - mean_absolute_error: 0.0102 - val_loss: 7.5975e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.00007\n",
      "Epoch 399/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.7036e-04 - mean_absolute_error: 0.0106 - val_loss: 8.2925e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.00007\n",
      "Epoch 400/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.6406e-04 - mean_absolute_error: 0.0104 - val_loss: 9.1878e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.00007\n",
      "Epoch 401/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.7430e-04 - mean_absolute_error: 0.0106 - val_loss: 7.3163e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.00007\n",
      "Epoch 402/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.7454e-04 - mean_absolute_error: 0.0104 - val_loss: 9.3797e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.00007\n",
      "Epoch 403/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.7086e-04 - mean_absolute_error: 0.0103 - val_loss: 7.5035e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.00007\n",
      "Epoch 404/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.5440e-04 - mean_absolute_error: 0.0101 - val_loss: 7.3728e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.00007\n",
      "Epoch 405/500\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 1.9042e-04 - mean_absolute_error: 0.0106 - val_loss: 8.3732e-05 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.00007\n",
      "Epoch 406/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.7507e-04 - mean_absolute_error: 0.0106 - val_loss: 7.2187e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00406: val_loss improved from 0.00007 to 0.00007, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 407/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.4034e-04 - mean_absolute_error: 0.0099 - val_loss: 8.8409e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.00007\n",
      "Epoch 408/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.7406e-04 - mean_absolute_error: 0.0102 - val_loss: 8.4335e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.00007\n",
      "Epoch 409/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.6466e-04 - mean_absolute_error: 0.0103 - val_loss: 7.7707e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.00007\n",
      "Epoch 410/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 2.0353e-04 - mean_absolute_error: 0.0109 - val_loss: 7.8135e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.00007\n",
      "Epoch 411/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.7830e-04 - mean_absolute_error: 0.0107 - val_loss: 8.7049e-05 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.00007\n",
      "Epoch 412/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.6977e-04 - mean_absolute_error: 0.0106 - val_loss: 8.9560e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.00007\n",
      "Epoch 413/500\n",
      "74/74 [==============================] - 13s 173ms/step - loss: 1.8084e-04 - mean_absolute_error: 0.0105 - val_loss: 8.5158e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.00007\n",
      "Epoch 414/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.5603e-04 - mean_absolute_error: 0.0101 - val_loss: 1.0786e-04 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.00007\n",
      "Epoch 415/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 2.0475e-04 - mean_absolute_error: 0.0109 - val_loss: 1.0667e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.00007\n",
      "Epoch 416/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.8841e-04 - mean_absolute_error: 0.0106 - val_loss: 8.1060e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.00007\n",
      "Epoch 417/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.6946e-04 - mean_absolute_error: 0.0104 - val_loss: 1.0625e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.00007\n",
      "Epoch 418/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.8652e-04 - mean_absolute_error: 0.0108 - val_loss: 7.4857e-05 - val_mean_absolute_error: 0.0058\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.00007\n",
      "Epoch 419/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.6151e-04 - mean_absolute_error: 0.0102 - val_loss: 8.1018e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.00007\n",
      "Epoch 420/500\n",
      "74/74 [==============================] - 13s 173ms/step - loss: 1.6296e-04 - mean_absolute_error: 0.0102 - val_loss: 8.4117e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.00007\n",
      "Epoch 421/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.8699e-04 - mean_absolute_error: 0.0106 - val_loss: 7.9693e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.00007\n",
      "Epoch 422/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.6834e-04 - mean_absolute_error: 0.0104 - val_loss: 1.2107e-04 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.00007\n",
      "Epoch 423/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 2.0608e-04 - mean_absolute_error: 0.0112 - val_loss: 7.8089e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.00007\n",
      "Epoch 424/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.7110e-04 - mean_absolute_error: 0.0104 - val_loss: 6.9087e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00424: val_loss improved from 0.00007 to 0.00007, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 425/500\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 1.7167e-04 - mean_absolute_error: 0.0106 - val_loss: 1.0590e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.00007\n",
      "Epoch 426/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.5507e-04 - mean_absolute_error: 0.0101 - val_loss: 9.2729e-05 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.00007\n",
      "Epoch 427/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.6873e-04 - mean_absolute_error: 0.0104 - val_loss: 7.5071e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.00007\n",
      "Epoch 428/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.5855e-04 - mean_absolute_error: 0.0103 - val_loss: 8.2387e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.00007\n",
      "Epoch 429/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.5653e-04 - mean_absolute_error: 0.0100 - val_loss: 8.2215e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.00007\n",
      "Epoch 430/500\n",
      "74/74 [==============================] - 13s 171ms/step - loss: 1.5892e-04 - mean_absolute_error: 0.0101 - val_loss: 8.2850e-05 - val_mean_absolute_error: 0.0082\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.00007\n",
      "Epoch 431/500\n",
      "74/74 [==============================] - 13s 173ms/step - loss: 1.6066e-04 - mean_absolute_error: 0.0103 - val_loss: 7.5644e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.00007\n",
      "Epoch 432/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.6743e-04 - mean_absolute_error: 0.0103 - val_loss: 7.4707e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.00007\n",
      "Epoch 433/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.4926e-04 - mean_absolute_error: 0.0101 - val_loss: 7.6137e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.00007\n",
      "Epoch 434/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.5656e-04 - mean_absolute_error: 0.0104 - val_loss: 6.6290e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00434: val_loss improved from 0.00007 to 0.00007, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 435/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.7820e-04 - mean_absolute_error: 0.0106 - val_loss: 6.8861e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.00007\n",
      "Epoch 436/500\n",
      "74/74 [==============================] - 12s 168ms/step - loss: 1.5999e-04 - mean_absolute_error: 0.0102 - val_loss: 1.6597e-04 - val_mean_absolute_error: 0.0098\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.00007\n",
      "Epoch 437/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.7216e-04 - mean_absolute_error: 0.0107 - val_loss: 9.2613e-05 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.00007\n",
      "Epoch 438/500\n",
      "74/74 [==============================] - 13s 173ms/step - loss: 1.8906e-04 - mean_absolute_error: 0.0108 - val_loss: 8.2172e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.00007\n",
      "Epoch 439/500\n",
      "74/74 [==============================] - 13s 169ms/step - loss: 1.7726e-04 - mean_absolute_error: 0.0104 - val_loss: 7.6652e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.00007\n",
      "Epoch 440/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.6632e-04 - mean_absolute_error: 0.0102 - val_loss: 8.5871e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.00007\n",
      "Epoch 441/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.8070e-04 - mean_absolute_error: 0.0108 - val_loss: 7.2028e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.00007\n",
      "Epoch 442/500\n",
      "74/74 [==============================] - 13s 170ms/step - loss: 1.6568e-04 - mean_absolute_error: 0.0102 - val_loss: 6.8745e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.00007\n",
      "Epoch 443/500\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 1.7006e-04 - mean_absolute_error: 0.0102 - val_loss: 8.0657e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.00007\n",
      "Epoch 444/500\n",
      "74/74 [==============================] - 13s 172ms/step - loss: 1.4750e-04 - mean_absolute_error: 0.0099 - val_loss: 6.5111e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00444: val_loss improved from 0.00007 to 0.00007, saving model to results/2021-01-10_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 445/500\n",
      "74/74 [==============================] - 12s 169ms/step - loss: 1.2619e-04 - mean_absolute_error: 0.0094 - val_loss: 6.7945e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.00007\n",
      "Epoch 446/500\n",
      "56/74 [=====================>........] - ETA: 2s - loss: 1.3987e-04 - mean_absolute_error: 0.0098"
     ]
    }
   ],
   "source": [
    "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n",
    "                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n",
    "                feature_columns=FEATURE_COLUMNS)\n",
    "# save the dataframe\n",
    "data[\"df\"].to_csv(ticker_data_filename)\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "# train the model and save the weights whenever we see \n",
    "# a new optimal model using ModelCheckpoint\n",
    "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
    "                    callbacks=[checkpointer, tensorboard],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.4.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=\"logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graph(test_df):\n",
    "    \"\"\"\n",
    "    This function plots true close price along with predicted close price\n",
    "    with blue and red colors respectively\n",
    "    \"\"\"\n",
    "    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n",
    "    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_df(model, data):\n",
    "    \"\"\"\n",
    "    This function takes the `model` and `data` dict to \n",
    "    construct a final dataframe that includes the features along \n",
    "    with true and predicted prices of the testing dataset\n",
    "    \"\"\"\n",
    "    # if predicted future price is higher than the current, \n",
    "    # then calculate the true future price minus the current price, to get the buy profit\n",
    "    buy_profit  = lambda current, true_future, pred_future: true_future - current if pred_future > current else 0\n",
    "    # if the predicted future price is lower than the current price,\n",
    "    # then subtract the true future price from the current price\n",
    "    sell_profit = lambda current, true_future, pred_future: current - true_future if pred_future < current else 0\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_test = data[\"y_test\"]\n",
    "    # perform prediction and get prices\n",
    "    y_pred = model.predict(X_test)\n",
    "    if SCALE:\n",
    "        y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "        y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
    "    test_df = data[\"test_df\"]\n",
    "    # add predicted future prices to the dataframe\n",
    "    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n",
    "    # add true future prices to the dataframe\n",
    "    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n",
    "    # sort the dataframe by date\n",
    "    test_df.sort_index(inplace=True)\n",
    "    final_df = test_df\n",
    "    # add the buy profit column\n",
    "    final_df[\"buy_profit\"] = list(map(buy_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    # add the sell profit column\n",
    "    final_df[\"sell_profit\"] = list(map(sell_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    if SCALE:\n",
    "        predicted_price = data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n",
    "    else:\n",
    "        predicted_price = prediction[0][0]\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load optimal model weights from results folder\n",
    "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "loss, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "# calculate the mean absolute error (inverse scaling)\n",
    "if SCALE:\n",
    "    mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
    "else:\n",
    "    mean_absolute_error = mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = get_final_df(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_price = predict(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
    "# calculating total buy & sell profit\n",
    "total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
    "total_sell_profit = final_df[\"sell_profit\"].sum()\n",
    "# total profit by adding sell & buy together\n",
    "total_profit = total_buy_profit + total_sell_profit\n",
    "# dividing total profit by number of testing samples (number of trades)\n",
    "profit_per_trade = total_profit / len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future price after 15 days is 3219.31$\n",
      "huber_loss loss: 5.973030056338757e-05\n",
      "Mean Absolute Error: 21.424797895009252\n",
      "Accuracy score: 0.5415959252971138\n",
      "Total buy profit: 7902.505493406206\n",
      "Total sell profit: 476.0968904197216\n",
      "Total profit: 8378.602383825928\n",
      "Profit per trade: 7.112565690853929\n"
     ]
    }
   ],
   "source": [
    "# printing metrics\n",
    "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n",
    "print(f\"{LOSS} loss:\", loss)\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error)\n",
    "print(\"Accuracy score:\", accuracy_score)\n",
    "print(\"Total buy profit:\", total_buy_profit)\n",
    "print(\"Total sell profit:\", total_sell_profit)\n",
    "print(\"Total profit:\", total_profit)\n",
    "print(\"Profit per trade:\", profit_per_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graph(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   open         high          low        close     adjclose  \\\n",
      "2020-10-13  3467.989990  3492.379883  3424.219971  3443.629883  3443.629883   \n",
      "2020-10-16  3363.229980  3399.659912  3160.000000  3272.709961  3272.709961   \n",
      "2020-10-20  3222.280029  3266.000000  3192.010010  3217.010010  3217.010010   \n",
      "2020-10-21  3212.500000  3233.879883  3160.000000  3184.939941  3184.939941   \n",
      "2020-10-27  3224.939941  3291.659912  3211.300049  3286.330078  3286.330078   \n",
      "2020-11-03  3018.530029  3074.899902  2980.979980  3048.409912  3048.409912   \n",
      "2020-11-10  3095.020020  3114.000000  3019.479980  3035.020020  3035.020020   \n",
      "2020-11-12  3159.949951  3175.879883  3086.050049  3110.280029  3110.280029   \n",
      "2020-11-23  3116.699951  3139.750000  3065.459961  3098.389893  3098.389893   \n",
      "2020-12-10  3088.989990  3142.100098  3076.000000  3101.489990  3101.489990   \n",
      "\n",
      "             volume ticker  adjclose_15  true_adjclose_15  buy_profit  \\\n",
      "2020-10-13  5744700   AMZN  3173.195312       3048.409912    0.000000   \n",
      "2020-10-16  6474400   AMZN  3195.598145       3311.370117  -77.111816   \n",
      "2020-10-20  4509700   AMZN  3202.194336       3035.020020    0.000000   \n",
      "2020-10-21  4592700   AMZN  3206.456055       3137.389893    0.000000   \n",
      "2020-10-27  4291000   AMZN  3200.942139       3135.659912    0.000000   \n",
      "2020-11-03  4897900   AMZN  3235.699707       3118.060059  187.289795   \n",
      "2020-11-10  6591000   AMZN  3226.791992       3203.530029  191.771973   \n",
      "2020-11-12  4362000   AMZN  3223.410156       3162.580078  113.130127   \n",
      "2020-11-23  4708900   AMZN  3231.235352       3165.120117  132.845459   \n",
      "2020-12-10  3030200   AMZN  3226.850342       3186.629883  125.360352   \n",
      "\n",
      "            sell_profit  \n",
      "2020-10-13   270.434570  \n",
      "2020-10-16     0.000000  \n",
      "2020-10-20    14.815674  \n",
      "2020-10-21   -21.516113  \n",
      "2020-10-27    85.387939  \n",
      "2020-11-03     0.000000  \n",
      "2020-11-10     0.000000  \n",
      "2020-11-12     0.000000  \n",
      "2020-11-23     0.000000  \n",
      "2020-12-10     0.000000  \n"
     ]
    }
   ],
   "source": [
    "print(final_df.tail(10))\n",
    "# save the final dataframe to csv-results folder\n",
    "csv_results_folder = \"csv-results\"\n",
    "if not os.path.isdir(csv_results_folder):\n",
    "    os.mkdir(csv_results_folder)\n",
    "csv_filename = os.path.join(csv_results_folder, model_name + \".csv\")\n",
    "final_df.to_csv(csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
